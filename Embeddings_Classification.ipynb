{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60da6232",
   "metadata": {},
   "source": [
    "# Embedding and Classification Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95a0538",
   "metadata": {},
   "source": [
    "This notebook contains multiple embedding methods and one Classification method (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75131984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snap \n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "#from deepwalk import DeepWalk\n",
    "#from graphembedding.sdne import SDNE\n",
    "#from gem.embedding.hope import HOPE\n",
    "\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "#from GraphEmbedding.ge import LINE, SDNE, Struc2Vec\n",
    "from joblib import parallel_config\n",
    "from karateclub import SINE, AE, HOPE\n",
    "\n",
    "\n",
    "\n",
    "%run Fairness.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa43ca9",
   "metadata": {},
   "source": [
    "**Emebedding node2Vec:**\n",
    "- this method creates an embedding of a graph by using the Node2Vec Algorithm\n",
    "- returns an emebdding matrix of the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87889c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emebedding_node2Vec(graph, dimensions, walk_length, num_walks, workers):\n",
    "    node2vec = Node2Vec(graph, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, workers=workers)\n",
    "\n",
    "    #Fit the Node2Vec model to the graph\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "    # Obtain node embeddings\n",
    "    node_embeddings = {str(node): model.wv[str(node)] for node in graph.nodes()}\n",
    "    embedding_matrix = np.array(list(node_embeddings.values()))\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ce4f8",
   "metadata": {},
   "source": [
    "**DeepWalk:**\n",
    "- calculates the emebedding of each nodes by calculating random walks for every node\n",
    "- returns: embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9067a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepWalk_(graph, number_of_random_walks, walk_length, window):\n",
    "    # calculate random walks for every node in the Graph\n",
    "    all_nodes = list(graph.nodes())\n",
    "    #number_of_random_walks = 5\n",
    "    random_walks = []\n",
    "    print(number_of_random_walks)\n",
    "    print(walk_length)\n",
    "    print(window)\n",
    "\n",
    "    for node in tqdm(all_nodes):\n",
    "        # number of random walks\n",
    "        for i in range(number_of_random_walks):\n",
    "            # append the random walk sequence of a node from a specified length\n",
    "            random_walks.append(get_random_walk(graph, node, walk_length))\n",
    "    \n",
    "        # train word2vec model\n",
    "    model = Word2Vec(window = window, sg = 1, hs = 0,negative = 10, alpha=0.03, min_alpha=0.0007)\n",
    "\n",
    "    model.build_vocab(random_walks, progress_per=2)\n",
    "    \n",
    "    model.train(random_walks, total_examples = model.corpus_count, epochs=20, report_delay=1)\n",
    "    # Get embeddings for nodes\n",
    "    embeddings = model.wv\n",
    "    return embeddings\n",
    "    \n",
    "# function to generate random walk sequences of nodes for a particular node\n",
    "def get_random_walk(graph, node, walk_length):\n",
    "    # initialization\n",
    "    random_walk_length = [node]\n",
    "    \n",
    "    #loop over to get the nodes visited in a random walk\n",
    "    for i in range(walk_length-1):\n",
    "        # list of neighbors\n",
    "        neighbors = list(graph.neighbors(node))\n",
    "        # if the same neighbors are present in ranom_walk_length list, then donot add them as new neighbors\n",
    "        neighbors = list(set(neighbors) - set(random_walk_length))    \n",
    "        if len(neighbors) == 0:\n",
    "            break\n",
    "        # pick any one neighbor randomly from the neighbors list\n",
    "        random_neighbor = random.choice(neighbors)\n",
    "        # append that random_neighbor to the random_walk_length list\n",
    "        random_walk_length.append(random_neighbor)\n",
    "        node = random_neighbor\n",
    "        \n",
    "    return random_walk_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096039c5",
   "metadata": {},
   "source": [
    "**SINE**:\n",
    "-  this method creates an attributed embedding by learning a low dimensional vector representation\n",
    "- returns an emebdding matrix of the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8168f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine(graph, coo_matrix, **params): \n",
    "    model = SINE(**params)\n",
    "    model.fit(graph, coo_matrix,)\n",
    "    embedding = model.get_embedding()\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a3ed5",
   "metadata": {},
   "source": [
    "**Attributed Emebdding**\n",
    "- creates a low dimesnional representation fo nodes by considering node attributes (coo_matrix)\n",
    "- returns an emebdding matrix of the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43cb8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae(graph, coo_matrix, **params): \n",
    "    model = AE(**params)\n",
    "    model.fit(graph, coo_matrix,)\n",
    "    embedding = model.get_embedding()\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61faec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def deepWalk_embedding(graph):\n",
    "#     num_walks = 10\n",
    "#     walk_length = 30\n",
    "\n",
    "#     # Train DeepWalk\n",
    "#     model = DeepWalk(G, num_walks=num_walks, walk_length=walk_length, workers=4)\n",
    "#     model.train(window_size=5, iter=1)  # You can adjust window_size and iter based on your needs\n",
    "\n",
    "#     # Get embeddings for nodes\n",
    "#     embeddings = model.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6620e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hope_embedding(graph, **params):\n",
    "    # Train Hope\n",
    "    #d=64, beta=0.01\n",
    "    \n",
    "    # Step: Construct High-Order Adjacency Matrix (Using Random Walks)\n",
    "    # Construct a high-order adjacency matrix capturing higher-order proximity information\n",
    "    # Here, we'll use the karateclub library's Hope implementation for simplicity\n",
    "    hope = HOPE(**params)  # You can adjust the embedding dimension 'd' and 'beta' based on your needs\n",
    "    hope.fit(graph)\n",
    "\n",
    "   \n",
    "\n",
    "    # Step: Apply Hope Embedding\n",
    "    # Learn low-dimensional representations (embeddings) for each node in the graph\n",
    "    # This will preserve both local and global structural information\n",
    "    node_embeddings = hope.get_embedding()\n",
    "    \n",
    "    \n",
    "    return node_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f7741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e6278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c1bf2d8",
   "metadata": {},
   "source": [
    "**Classification SVM**\n",
    "- seperates the dataset into trainings and test dataset\n",
    "- creates SVM classifier\n",
    "- train the classifier on trainings dataset\n",
    "- makes a prediction on the test dataset\n",
    "- returns: prediction, true labels,  indices of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b3cef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call classification method\n",
    "def classification_SVM(embedding_matrix, labels):\n",
    "    labels_array = np.array(labels)\n",
    "    print(labels_array)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices  = splitdataset(embedding_matrix,labels_array )\n",
    "    #print(X_train)\n",
    "    #print('hhs')\n",
    "    #print(X_test)\n",
    "    #print('hhs')\n",
    "    #print(y_train)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    svm_classifier = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "    # Train the classifier\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = svm_classifier.predict(X_test)\n",
    "    \n",
    "    return predictions, y_test, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a9bc3",
   "metadata": {},
   "source": [
    "**Splitdatset:**\n",
    "- split the datset in to trainings and testdatset\n",
    "- returns: lists of trainings data/label and test data/label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51238b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitdataset(embeddings, labels):\n",
    "    num_samples = len(labels)\n",
    "\n",
    "    # num_train_samples: the number of data points you want in your training set (e.g., 80% of the data)\n",
    "    num_train_samples = int(0.7 * num_samples)\n",
    "    \n",
    "    train_indices = np.random.choice(num_samples, size=num_train_samples, replace=False)\n",
    "    test_indices = np.setdiff1d(np.arange(num_samples), train_indices)\n",
    "    #print('train_indices')\n",
    "    #print(train_indices)\n",
    "    \n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    test_embeddings = []\n",
    "    for indices in train_indices:\n",
    "       # print(embeddings[indices])\n",
    "        #print('jdj')\n",
    "        train_embeddings.append(embeddings[indices])\n",
    "        train_labels.append(labels[indices])\n",
    "    for indices in test_indices:\n",
    "        test_embeddings.append(embeddings[indices])\n",
    "        test_labels.append(labels[indices])\n",
    "    #print(len(labels))\n",
    "    #print(len(train_labels))\n",
    "    #print(len(test_labels))\n",
    "        \n",
    "    if((num_samples == len(train_indices)+ len(test_indices)) and (len(labels) == (len(train_indices)+ len(test_indices)))):\n",
    "            return train_embeddings, test_embeddings, train_labels, test_labels, train_indices, test_indices\n",
    "    else:\n",
    "        return null, null, null, null, null, null\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f921a",
   "metadata": {},
   "source": [
    "**Hope Grid search**:\n",
    "- apply a grid search alogorithm on the Hope algorithm to find the best parameters of the best result\n",
    "- returns best parameters, best FPR for female and male, Dataframe with the results of each fairness definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8068beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hope_grid_search(G_nx, parameter_grid, df_target, gender):\n",
    "    best_params = None\n",
    "    best_fpr_f = 2.0\n",
    "    best_fpr_m = 2.0\n",
    "    best_predictions_node2Vec = []\n",
    "    best_y_test = []\n",
    "    test_indices = []\n",
    "    dataframe = pd.DataFrame()\n",
    "\n",
    "    for params in ParameterGrid(parameter_grid):\n",
    "        # Initialisieren Sie Node2Vec mit den aktuellen Parametern\n",
    "        embeddingMA_deepWalk = hope_embedding(G_nx, **params)\n",
    "\n",
    "        predictions, y_test, test_indices  = classification_SVM(embeddingMA_deepWalk, list(df_target))\n",
    "        y_pred_f, y_pred_m, y_true_f, y_true_m = seperate_female_male(predictions, y_test, test_indices,list(gender))\n",
    "        fpF, fp_m = false_positive_error_rate_balance(y_true_f, y_pred_f, y_true_m, y_pred_m)\n",
    "        print('fpF:', fpF)\n",
    "        print('fpM:', fp_m)\n",
    "        dataframe_evaluation_DeepWalk = return_frame_with_evaluations(predictions, y_test, test_indices, list(gender))\n",
    "        \n",
    "        if best_fpr_f > fpF and best_fpr_m > fp_m:\n",
    "            best_fpr_f = fpF\n",
    "            best_fpr_m = fp_m\n",
    "            best_params = params\n",
    "            best_predictions_node2Vec = predictions\n",
    "            best_y_test = y_test\n",
    "            test_indices = test_indices\n",
    "            dataframe = dataframe_evaluation_DeepWalk\n",
    "\n",
    "    return best_params, best_fpr_f,best_fpr_m, dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71c23c",
   "metadata": {},
   "source": [
    "**peform Grid search DeepWalk**:\n",
    "- apply a grid search alogorithm on the DeepWalk algorithm to find the best parameters of the best result\n",
    "- returns best parameters, best FPR for female and male, Dataframe with the results of each fairness definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9769aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search_DeepWalk(G_nx, parameter_grid, df_target, gender):\n",
    "    best_params = None\n",
    "    best_fpr_f = 2.0\n",
    "    best_fpr_m = 2.0\n",
    "    best_predictions_node2Vec = []\n",
    "    best_y_test = []\n",
    "    test_indices = []\n",
    "    dataframe = pd.DataFrame()\n",
    "\n",
    "    for params in ParameterGrid(parameter_grid):\n",
    "        # Initialisieren Sie Node2Vec mit den aktuellen Parametern\n",
    "        embeddingMA_deepWalk = deepWalk_(G_nx, **params)\n",
    "\n",
    "        predictions, y_test, test_indices  = classification_SVM(embeddingMA_deepWalk, list(df_target))\n",
    "        y_pred_f, y_pred_m, y_true_f, y_true_m = seperate_female_male(predictions, y_test, test_indices,list(gender))\n",
    "        fpF, fp_m = false_positive_error_rate_balance(y_true_f, y_pred_f, y_true_m, y_pred_m)\n",
    "        print('fpF:', fpF)\n",
    "        print('fpM:', fp_m)\n",
    "        dataframe_evaluation_DeepWalk = return_frame_with_evaluations(predictions, y_test, test_indices, list(gender))\n",
    "        \n",
    "        if best_fpr_f > fpF and best_fpr_m > fp_m:\n",
    "            best_fpr_f = fpF\n",
    "            best_fpr_m = fp_m\n",
    "            best_params = params\n",
    "            best_predictions_node2Vec = predictions\n",
    "            best_y_test = y_test\n",
    "            test_indices = test_indices\n",
    "            dataframe = dataframe_evaluation_DeepWalk\n",
    "\n",
    "    return best_params, best_fpr_f,best_fpr_m, dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b05b63",
   "metadata": {},
   "source": [
    "**peform Grid search**:\n",
    "- apply a grid search alogorithm on the Struc2Vec algorithm to find the best parameters of the best result\n",
    "- returns best parameters, best FPR for female and male, Dataframe with the results of each fairness definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae45daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(G_nx, parameter_grid, df_target, gender):\n",
    "    best_params = None\n",
    "    best_fpr_f = 2\n",
    "    best_fpr_m = 2\n",
    "    best_predictions_node2Vec = []\n",
    "    best_y_test = []\n",
    "    test_indices = []\n",
    "    dataframe = []\n",
    "\n",
    "    for params in ParameterGrid(parameter_grid):\n",
    "        # Initialisieren Sie Node2Vec mit den aktuellen Parametern\n",
    "        \n",
    "        embeddingMA_node2Vec = emebedding_node2Vec(G_nx, **params)\n",
    "        #print(embeddingMA_node2Vec)\n",
    "        print('done create embeding vectors')\n",
    "        predictions, y_test, test_indices  = classification_SVM(embeddingMA_node2Vec, list(df_target))\n",
    "        y_pred_f, y_pred_m, y_true_f, y_true_m = seperate_female_male(predictions, y_test, test_indices, list(gender))\n",
    "        \n",
    "        fpF, fp_m = false_positive_error_rate_balance(y_true_f, y_pred_f, y_true_m, y_pred_m)\n",
    "        print('done iteration')\n",
    "        dataframe_evaluation_Node2Vec = return_frame_with_evaluations(predictions, y_test, test_indices, list(gender))\n",
    "        print('fpF:', fpF)\n",
    "        print('fpM:', fp_m)\n",
    "        \n",
    "        if best_fpr_f > fpF and best_fpr_m > fp_m:\n",
    "            best_fpr_f = fpF\n",
    "            best_fpr_m = fp_m\n",
    "            best_params = params\n",
    "            best_predictions_node2Vec = predictions\n",
    "            best_y_test = y_test\n",
    "            test_indices = test_indices\n",
    "            dataframe = dataframe_evaluation_Node2Vec\n",
    "\n",
    "    return best_params, best_fpr_f,best_fpr_m, dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f67626",
   "metadata": {},
   "source": [
    "**Grid search SINE:**\n",
    "- apply a grid search alogorithm on the SINE algorithm to find the best parameters of the best result\n",
    "- returns best parameters, best FPR for female and male, Dataframe with the results of each fairness definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4da1f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_SINE(G_nx, features, parameter_grid, df_target, gender):\n",
    "    best_params = None\n",
    "    best_fpr_f = 2\n",
    "    best_fpr_m = 2\n",
    "    best_predictions= []\n",
    "    best_y_test = []\n",
    "    test_indices = []\n",
    "    dataframe = []\n",
    "    \n",
    "    for params in ParameterGrid(parameter_grid):\n",
    "        # Initialisieren Sie Node2Vec mit den aktuellen Parametern\n",
    "        \n",
    "        embeddingMA  = sine(G_nx, coo_matrix, **params)\n",
    "        #print(embeddingMA_node2Vec)\n",
    "        print('done create embeding vectors')\n",
    "        predictions, y_test, test_indices  = classification_SVM(embeddingMA, list(df_target))\n",
    "        y_pred_f, y_pred_m, y_true_f, y_true_m = seperate_female_male(predictions, y_test, test_indices, list(gender))\n",
    "        \n",
    "        fpF, fp_m = false_positive_error_rate_balance(y_true_f, y_pred_f, y_true_m, y_pred_m)\n",
    "        print('done iteration')\n",
    "        dataframe_evaluation = return_frame_with_evaluations(predictions, y_test, test_indices, list(gender))\n",
    "        print('fpF:', fpF)\n",
    "        print('fpM:', fp_m)\n",
    "        \n",
    "        if best_fpr_f > fpF and best_fpr_m > fp_m:\n",
    "            best_fpr_f = fpF\n",
    "            best_fpr_m = fp_m\n",
    "            best_params = params\n",
    "            best_predictions = predictions\n",
    "            best_y_test = y_test\n",
    "            test_indices = test_indices\n",
    "            dataframe = dataframe_evaluation\n",
    "            \n",
    "    return best_params, best_fpr_f,best_fpr_m, dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf793f1",
   "metadata": {},
   "source": [
    "**Grid search AE**:\n",
    "- apply a grid search alogorithm on the AE algorithm to find the best parameters of the best result\n",
    "- returns best parameters, best FPR for female and male, Dataframe with the results of each fairness definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b22b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_AE(G_nx, features, parameter_grid, df_target, gender):\n",
    "    best_params = None\n",
    "    best_fpr_f = 2\n",
    "    best_fpr_m = 2\n",
    "    best_predictions= []\n",
    "    best_y_test = []\n",
    "    test_indices = []\n",
    "    dataframe = []\n",
    "    \n",
    "    for params in ParameterGrid(parameter_grid):\n",
    "        # Initialisieren Sie Node2Vec mit den aktuellen Parametern\n",
    "        \n",
    "        embeddingMA  = ae(G_nx, coo_matrix, **params)\n",
    "        #print(embeddingMA_node2Vec)\n",
    "        print('done create embeding vectors')\n",
    "        predictions, y_test, test_indices  = classification_SVM(embeddingMA, list(df_target))\n",
    "        y_pred_f, y_pred_m, y_true_f, y_true_m = seperate_female_male(predictions, y_test, test_indices, list(gender))\n",
    "        \n",
    "        fpF, fp_m = false_positive_error_rate_balance(y_true_f, y_pred_f, y_true_m, y_pred_m)\n",
    "        print('done iteration')\n",
    "        dataframe_evaluation = return_frame_with_evaluations(predictions, y_test, test_indices, list(gender))\n",
    "        print('fpF:', fpF)\n",
    "        print('fpM:', fp_m)\n",
    "        \n",
    "        if best_fpr_f > fpF and best_fpr_m > fp_m:\n",
    "            best_fpr_f = fpF\n",
    "            best_fpr_m = fp_m\n",
    "            best_params = params\n",
    "            best_predictions = predictions\n",
    "            best_y_test = y_test\n",
    "            test_indices = test_indices\n",
    "            dataframe = dataframe_evaluation\n",
    "            \n",
    "    return best_params, best_fpr_f,best_fpr_m, dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
