# Fair_node_Classification
## Abstract
Machine learning (ML) is integral for predictions and classifications but confronts challenges tied to bias, particularly affecting underrepresented groups. These encompass diverse ethnicities, foreigners, and individuals with disabilities. ML's role in network analysis, focusing on graph structures, introduces embedding methods representing nodes and relationships in a lower-dimensional space. However, these algorithms may encode biases, necessitating research to identify fair embedding methods.
This experiment investigates the fairness of four embedding methods across five diverse datasets, utilizing metrics proposed by Verma and Rubin with a primary focus on gender-related fairness. Beyond predictive accuracy, the study employs benchmarks to ensure comprehensive examinations. Insights from 5x4 experiments aim to contribute to fair and unbiased decision-making algorithms, promoting inclusivity in ML applications, particularly addressing gender-related considerations. 
The results showed that each embedding method exhibited different levels of fairness across the diverse datasets. However, two of the methods were slightly more significantly fairer than the others in terms of gender considerations. The two methods are Node2Vec and DeepWalk. There achieved the most consistent and best predicted results. 


## Note
The Twitch Dataset is to big and I can not upload it. I tried everything but it did not work. The link to the dataset is here: https://snap.stanford.edu/data/twitch-social-networks.html. 
