{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0de39d",
   "metadata": {},
   "source": [
    "# Fairness Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d3186",
   "metadata": {},
   "source": [
    "This method contains multiple methods to estimate if the emebedding is fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c196763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snap \n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import networkx as nx\n",
    "import sklearn.metrics as skl_metrics\n",
    "import numpy as np\n",
    "#import fairlearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57334a42",
   "metadata": {},
   "source": [
    "**ConfusionMatrix:** creates based in the prediction and the true labels a Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0416d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(y_true, y_pred, labels=None):\n",
    "    if(len(y_true) != 0) and (len(y_pred) != 0):\n",
    "        #print(y_true,y_pred)\n",
    "        y_true = np.array(y_true, dtype=int)  # Convert string values to integers\n",
    "        y_pred = np.array(y_pred, dtype=int)\n",
    "        matrix =  skl_metrics.confusion_matrix(y_true, y_pred, labels=[0, 1], sample_weight=None, normalize=None)\n",
    "        print(matrix)\n",
    "        tn, fp, fn, tp = matrix.ravel()\n",
    "        return tn, fp, fn, tp\n",
    "    else:\n",
    "        return 0,0,0,0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95858d",
   "metadata": {},
   "source": [
    "**Predictive Parity:** \n",
    "- claculates the Positvive Predictive Value for each group (fermale and male)\n",
    "- returns: PPV for male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3073662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate PPV for each group\n",
    "#protected and unprotected group have equal PPV\n",
    "\n",
    "def predictive_Parity(y_true_f, y_pred_f, y_true_m, y_pred_m):\n",
    "    #print('y_true_f: ', len(y_true_f))\n",
    "    #print('y_pred_f: ',len(y_pred_f))\n",
    "    #print('y_true_m: ',len(y_true_m))\n",
    "    #print('y_pred_m: ',len(y_pred_m))\n",
    "    ppv_f = 0\n",
    "    ppv_m = 0\n",
    "    if(len(y_true_f) != 0) and  (len(y_pred_f) != 0):\n",
    "      \n",
    "        tn_f, fp_f, fn_f, tp_f = confusionMatrix(y_true_f,y_pred_f)\n",
    "        if(tp_f != 0):\n",
    "            ppv_f = tp_f/(tp_f + fp_f)\n",
    "    if(len(y_true_m) != 0) and  (len(y_pred_m) != 0):\n",
    "      \n",
    "        tn_m, fp_m, fn_m, tp_m = confusionMatrix(y_true_m,y_pred_m)\n",
    "        if(tp_m != 0):\n",
    "            ppv_m = tp_m/(tp_m + fp_m)\n",
    "      \n",
    "    return ppv_f, ppv_m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38fd1e4",
   "metadata": {},
   "source": [
    "**False Positve Error Rate Balance:**\n",
    "- claculates the False positive rate for each group (fermale and male)\n",
    "- returns: FPR for male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f32aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#False positive rate for each group\n",
    "def false_positive_error_rate_balance(y_true_f, y_pred_f, y_true_m, y_pred_m):\n",
    "    \n",
    "    fpr_f = 0\n",
    "    fpr_m = 0\n",
    "    if ((len(y_true_f) != 0) and  (len(y_pred_f) != 0)):\n",
    "        #print(confusionMatrix(y_true_f,y_pred_f))\n",
    "        print(y_true_f)\n",
    "        print('predic')\n",
    "        print(y_pred_f)\n",
    "        tn_f, fp_f, fn_f, tp_f = confusionMatrix(y_true_f,y_pred_f)\n",
    "        fpr_f = fp_f/(tn_f + fp_f)\n",
    "        \n",
    "    if(len(y_true_m) != 0) and  (len(y_pred_m) != 0):\n",
    "      \n",
    "        tn_m, fp_m, fn_m, tp_m = confusionMatrix(y_true_m,y_pred_m)\n",
    "        fpr_m = fp_m/(tn_m + fp_m)\n",
    "    \n",
    "    return fpr_f, fpr_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e796db",
   "metadata": {},
   "source": [
    "**Check Equal Probability:**\n",
    "- checks if the probability is equal for each group\n",
    "- returns true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0186db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the probability is equal\n",
    "def check_Equal_Probability(PPV_f, PPV_m):\n",
    "    return PPV_f == PPV_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0896264",
   "metadata": {},
   "source": [
    "**Group Fairness**:\n",
    "- calculate the probability of being assigned to a positive predicted class for each group (female and male)\n",
    "- returns the probabillity for female and male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb1043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_Fairness(y_true_f, y_true_m):\n",
    "    f_1 = y_true_f.count(1)\n",
    "    f_2 = y_true_m.count(1)\n",
    "    #print(f_1)\n",
    "    #print(f_2)\n",
    "    if(f_1 + f_2 == 0):\n",
    "        probF_PC = 0\n",
    "        probM_PC = 0\n",
    "    else:\n",
    "        probF_PC = f_1/(f_1 + f_2)\n",
    "        probM_PC = f_2/(f_1 + f_2)\n",
    "        \n",
    "    \n",
    "    return probF_PC, probM_PC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d3db00",
   "metadata": {},
   "source": [
    "**Equalized Opporrtunity**:\n",
    "- calcaulates the False Negative Rate for each group (female and male)\n",
    "- returns: FNR for male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4218b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_opportunity(y_true_f, y_pred_f, y_true_m, y_pred_m):\n",
    "    \n",
    "    fnr_f=0\n",
    "    fnr_m = 0\n",
    "    if(len(y_true_f) != 0) and  (len(y_pred_f) != 0):\n",
    "      \n",
    "        tn_f, fp_f, fn_f, tp_f = confusionMatrix(y_true_f,y_pred_f)\n",
    "        fnr_f = fn_f / (tp_f + fn_f)\n",
    "        \n",
    "    if(len(y_true_m) != 0) and  (len(y_pred_m) != 0):\n",
    "      \n",
    "        tn_m, fp_m, fn_m, tp_m = confusionMatrix(y_true_m,y_pred_m)\n",
    "        fnr_m = fn_m / (tp_m + fn_m)\n",
    "    \n",
    "    return fnr_f, fnr_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509adb08",
   "metadata": {},
   "source": [
    "**Equalized Odds:**\n",
    "- calculates FPR and TPR for each group\n",
    "- returns: FPR and TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737f5583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_odds(y_true_f, y_pred_f, y_true_m, y_pred_m):\n",
    "    ppv_f = 0\n",
    "    ppv_m = 0\n",
    "    fpr_f= 0\n",
    "    fpr_m = 0\n",
    "        \n",
    "    if(len(y_true_f) != 0) and  (len(y_pred_f) != 0):\n",
    "      \n",
    "        tn_f, fp_f, fn_f, tp_f = confusionMatrix(y_true_f,y_pred_f)\n",
    "        ppv_f = tp_f/(tp_f + fn_f)\n",
    "        fpr_f = fp_f/(tn_f + fp_f)\n",
    "        \n",
    "    if(len(y_true_m) != 0) and  (len(y_pred_m) != 0):\n",
    "      \n",
    "        tn_m, fp_m, fn_m, tp_m = confusionMatrix(y_true_m,y_pred_m)\n",
    "        ppv_m = tp_m/(tp_m + fn_m)\n",
    "        fpr_m = fp_m/(tn_m + fp_m)\n",
    "    \n",
    "    return ppv_f, ppv_m, fpr_f, fpr_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68313530",
   "metadata": {},
   "source": [
    "**Seperate Female and Male**:\n",
    "- this method divides the data into female/male predictions and labels\n",
    "- return: female, male prediction and labels as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "582001eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_female_male(prediction, labels, test_indices, gender):\n",
    "    #print(len(labels))\n",
    "    predictions_female = []\n",
    "    predictions_male = []\n",
    "    labels_female =[]\n",
    "    labels_male = []\n",
    "#     print(len(prediction))\n",
    "#     print(len(labels))\n",
    "#     print(len(test_indices))\n",
    "#     print(test_indices[-5:])\n",
    "    \n",
    "    #print(gender)\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        indices = test_indices[i]\n",
    "        if (gender[indices] == 0):\n",
    "#             print('in')\n",
    "#             print(prediction[i])\n",
    "            predictions_male.append(prediction[i])\n",
    "            labels_male.append(labels[i])\n",
    "        else:\n",
    "            predictions_female.append(prediction[i])\n",
    "            labels_female.append(labels[i])\n",
    "    \n",
    "    return predictions_female, predictions_male, labels_female, labels_male\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c0603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seperate_0_from_1(prediction, labels): \n",
    "#     zero_pred = []\n",
    "#     zero_label = []\n",
    "#     one_pred = []\n",
    "#     one_label = []\n",
    "#     for i in prediction:\n",
    "#         if(i == 0):\n",
    "#             zero_pred.append(i)\n",
    "#         else:\n",
    "#             one_pred.append(i)\n",
    "#     for k in labels:\n",
    "#         if(i == 0):\n",
    "#             zero_label.append(i)\n",
    "#         else:\n",
    "#             one_label.append(i)\n",
    "            \n",
    "    \n",
    "#     return zero_pred, zero_label, one_pred, one_label\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173a08b",
   "metadata": {},
   "source": [
    "**Count gender**:\n",
    "- count the number of female and males in the lists\n",
    "- return: 2 integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "085d1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_gender(list_gender):\n",
    "    print('jh')\n",
    "    list_gender = list(list_gender)\n",
    "    print(list_gender)\n",
    "    if type(list_gender) == 'String':\n",
    "        count_of_males = list_gender.count('0')\n",
    "        count_of_females = list_gender.count('1')\n",
    "        \n",
    "    else: \n",
    "        count_of_males = list_gender.count(0)\n",
    "        count_of_females = list_gender.count(1)\n",
    "    return count_of_females, count_of_males"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935bda23",
   "metadata": {},
   "source": [
    "**Return frrame with evaluation**:\n",
    "-  this methods creates a dataframe out of the results of the fairness methods\n",
    "- return: result dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "351f7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_frame_with_evaluations(predictions, target, test_indices, gender):\n",
    "    predictions_female, prediction_male, labels_female, labels_male = seperate_female_male(predictions, target, test_indices, list(gender))\n",
    "    \n",
    "    index = ['Group Fairness', 'Predictive Parity', 'False Positive Error Rate', 'Equalized Opportunity', 'Equalized Odds PPV', 'Equalized Odds FPR']\n",
    "    column = ['Female', 'Male']\n",
    "    dataFrame_result = pd.DataFrame(index =index )\n",
    "    \n",
    "    #zero_pred_f, zero_label_f, one_pred_f, one_label_f = seperate_0_from_1(predictions_female, labels_female)\n",
    "    #zero_pred_m, zero_label_m, one_pred_m, one_label_m = seperate_0_from_1(prediction_male, labels_male)\n",
    "\n",
    "    probF_PC, probM_PC = group_Fairness(predictions_female, prediction_male)\n",
    "    #print(probF_PC, probM_PC)\n",
    "    dataFrame_result.loc['Group Fairness', 'Female'] = probF_PC\n",
    "    dataFrame_result.loc['Group Fairness', 'Male'] = probM_PC\n",
    "    \n",
    "    PPV_f, PPV_m = predictive_Parity(labels_female, predictions_female, labels_male, prediction_male)\n",
    "    #print(PPV_f, PPV_m)\n",
    "    dataFrame_result.loc['Predictive Parity', 'Female'] = PPV_f\n",
    "    dataFrame_result.loc['Predictive Parity', 'Male'] = PPV_m\n",
    "    \n",
    "    print('PPV_f and PPV_m is equal:', check_Equal_Probability(PPV_f, PPV_m))\n",
    "    \n",
    "    fpr_f, fpr_m = false_positive_error_rate_balance(labels_female, predictions_female, labels_male, prediction_male)\n",
    "    #print(fpr_f, fpr_m)\n",
    "    dataFrame_result.loc['False Positive Error Rate', 'Female'] = fpr_f\n",
    "    dataFrame_result.loc['False Positive Error Rate', 'Male'] = fpr_m\n",
    "    \n",
    "    fnr_f, fnr_m = equalized_opportunity(labels_female, predictions_female, labels_male, prediction_male)\n",
    "    #print(fnr_f, fnr_m)\n",
    "    dataFrame_result.loc['Equalized Opportunity', 'Female'] = fnr_f\n",
    "    dataFrame_result.loc['Equalized Opportunity', 'Male'] = fnr_m\n",
    "    \n",
    "    ppv_f, ppv_m, fpr_f, fpr_m = equalized_odds(labels_female, predictions_female, labels_male, prediction_male)\n",
    "    #print(ppv_f, ppv_m, fpr_f, fpr_m)\n",
    "    dataFrame_result.loc['Equalized Odds PPV', 'Female'] = ppv_f\n",
    "    dataFrame_result.loc['Equalized Odds PPV', 'Male'] = ppv_m\n",
    "    dataFrame_result.loc['Equalized Odds FPR', 'Female'] = fpr_f\n",
    "    dataFrame_result.loc['Equalized Odds FPR', 'Male'] = fpr_m\n",
    "    \n",
    "    return dataFrame_result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
